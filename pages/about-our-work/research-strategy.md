#Draft Web Design Standards Research Strategy

##Overview
User research will be a core aspect of the Draft U.S. Web Design Standards project as it's the main source of feedback and inspiration for future product development. We want to use a mix of quantitative and qualitative methods so we have active and passive research going on a frequent basis. By conducting user research directly with users of the USWDS, we are able to get direct feedback on how the the standards are working for people when they encounter a site that's using it.

We are also able to provide user research services to teams that are using the USWDS, which are detailed below. These services will be priced and scoped so teams around the federal government are able to easily engage with us and find ways to improve their product. This benefits us as well as we get feedback on the various patterns and frameworks present in the design standards themselves.

##Analytics Reporting
_Quarterly Report Outs_

Once a quarter the metrics displayed on https://standards.usa.gov/about-our-work/ will be updated to reflect the recent traffic and usage of the Draft U.S. Web Design Standards. We will use this information to identify future improvements to the design patterns. You can use these metrics to help justify the adoption and continued use of the USWDS.

_Dependencies_
* The product team has defined the metrics and funnels you want to track and report out on
* One of product team members must be familiar enough with web analytics to set up the tracking and reporting

_References_
* https://www.nngroup.com/articles/analytics-reports-ux-strategists/
* http://www.uxbooth.com/articles/an-analytics-first-approach-to-ux-part-1/

##User Research Activities
_Recruitment_

One of our challenges is knowing who is interested in being part of our user research. To resolve this, we will implement several channels for federal designers and developers to signal their interest and provide their contact information to us. This will allow us to conduct research in a timely fashion.

_Potential Methods_
* Re-activate the screener to intercept users of standards.usa.gov
* Provide a "Contact Us" feature on standards.usa.gov
* Perform outreach via federal listservs and other digital channels to invite participation and collect contact information.

_Digital Service Team Remote Interviews_

One of the most consistent ways we have collected feedback from our users has been by conducting remote interviews with digital service teams around the federal government. This has allowed us to collect direct feedback and suggestions for how to improve the product. Given this success, the team aims to continue using this method on a frequent (1 - 2 interviews a month) basis.

_Bi-annual Contextual Inquiries_

Twice a year, the team will schedule a round of in-person interviews with teams around the federal government to meet with and observe how teams have been using, or would like to be using, the Draft U.S. Web Design Standards. The information gathered during these "contextual inquires" will ensure that the product is continuously delivering what federal teams and the general public need.

_Open House Events (with Remote Options)_

The team will host open house events at the GSA Headquarters in Washington D.C and remote using web conferencing tools. During these events, the team will conduct training presentations and allow teams using the USWDS to showcase their products and explain how they've implemented the Standards. These events will be open to anyone in federal government.

##Research as a Service Offerings

_Usability Testing_

The best method for us to learn how well the design patterns that are present in the Standards is to see them in action and observe people interacting with them. We would like to offer up a few usability study packages which teams using the USWDS can sign up for that would allow us to evaluate their solution and collect feedback the product and the patterns being used. This is a mutual benefit to us and teams around the federal government. We get direct feedback on how well our patterns work in different contexts and teams around the federal government get direct user feedback on their product.

###Package 1 - Remote Usability Evaluation
We will recruit users of your product and observe them using it using remote, online web conferencing, tools. The number of users involved will be no more than 20, depending on your user profiles and overall product needs. This evaluation is meant to highlight high level issues that are may be causing issues with your users and provide guidance on how to make future iterations of your product. The sessions will be open to your team for observation purposes and the team will report back any findings.

####Outcomes
* Detailed report highlight high level findings and recommendations for partner agency
* Report out on USWDS pattern usability and plan for refinement

####Cost and Timeline
Cost - $65,000 - $80,000
Timeline - 4 - 5 Weeks
Staff - 2 UX designers

###Package 2 - In-Person Usability Evaluation
We will recruit users of your product and observe them directly on location, where it makes sense. The number of users involved will be no more than 20, depending on your user profiles and overall product needs. This evaluation is meant to be an in-depth analysis of your product, exposing both general trends and specific issues that may be impacting your users. The sessions will be open to your team for observation purposes, on location and via remote conferencing tools, and the team will report back any findings.

####Outcomes
* Detailed usability findings of general trends and specific issues with recommendations for partner agency
* Report out on USWDS pattern usability and plan for refinement

####Cost and Timeline
Cost - $80,000 - $95,000 (travel costs included, additional recruitment and testing facility fees may apply)
Timeline - 5 - 6 Weeks
Staff - 2 UX designers

_Web Analytics Setup_

With the enrollment into the Data Analytics Platform (DAP) being part of the Policies for  <a href="https://www.whitehouse.gov/sites/default/files/omb/memoranda/2017/m-17-06.pdf">Federal Agency Public Websites and Digital Services</a> memo, we would like to provide an easy method and service to help digital services meet this requirement. Regardless if a team is using the USWDS or not, the integration into DAP should be consistent across the federal government and we have the tools and knowledge to help.

###Package 1 - DAP Integration
We will work with digital services teams to put the basic code needed into place for passing their web analytics into the DAP platform. This is a lightweight service meant to assist teams that don't have the necessary skills on hand to meet the policies requirements.

####Outcomes
* DAP code included on all required sites and pages.
* Integration into the DAP platform

####Cost and Timeline
Cost - $8,000 - $16,000
Timeline - 1 - 2 Weeks
Staff - 1 Analysts

###Package 2 - Basic Reporting and Dashboards
In addition to the services described in the above package, an analyst will work with a digital service team to set up basic reporting and dashboards that give agencies greater insight into how people use its digital products. The information gathered can help inform outreach, business and technical strategy, and user research activities the digital service team might want perform.

####Outcomes
* DAP code included on all required sites and pages.
* Integration into the DAP platform
* Requirements gathering of desired reports and dashboards
* Report and dashboard set up.

####Cost and Timeline
Cost - $24,000 - $31,000
Timeline - 3 - 4 Weeks
Staff - 1 Analysts
